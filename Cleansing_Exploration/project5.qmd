---
title: "Client Report - [The War With Star Wars]"
subtitle: "Course DS 250"
author: "[MIGUEL SMITH]"
format:
  html:
    self-contained: true
    page-layout: full
    title-block-banner: true
    toc: true
    toc-depth: 3
    toc-location: body
    number-sections: false
    html-math-method: katex
    code-fold: true
    code-summary: "Show the code"
    code-overflow: wrap
    code-copy: hover
    code-tools:
        source: false
        toggle: true
        caption: See code
execute: 
  warning: false
    
---

```{python}
import pandas as pd 
import numpy as np
import csv
from lets_plot import *
# add the additional libraries you need to import for ML here

LetsPlot.setup_html(isolated_frame=True)
```


## Elevator pitch
_A SHORT (2-3 SENTENCES) PARAGRAPH THAT `DESCRIBES KEY INSIGHTS` TAKEN FROM METRICS IN THE PROJECT RESULTS THINK TOP OR MOST IMPORTANT RESULTS._ (Note: this is not a summary of the project, but a summary of the results.)

After extensive clean-up of the data, the data can now be used for machine learning purposes. The model could be used to predict the parameter of Household income of $50k+ but it is not perfect. 

## QUESTION|TASK 1

__Shorten the column names and clean them up for easier use with pandas.__ Provide a table or list that exemplifies how you fixed the names. 

The columns were very messy, changes made in the code make the data easier to wrangle and visualize. Essentially each column header was changed.

```{python}
# Include and execute your code here
df_other = pd.read_csv("https://github.com/fivethirtyeight/data/raw/master/star-wars-survey/StarWars.csv", encoding_errors = "ignore",header = None,skiprows = 2)

df_starwars = pd.read_csv("https://github.com/fivethirtyeight/data/raw/master/star-wars-survey/StarWars.csv", encoding_errors = "ignore", nrows=1).melt()
pd.set_option("display.max_columns",None)
df_starwars = (
df_starwars.replace("Response", "")
       .replace(np.nan, "")
       .replace("^Unnamed.*", "", regex = True)
       .replace(r"Star Wars: (Episode \w{1,3}) .*", r"\1", regex = True)
)

df_starwars.iloc[3:9, 0] = "seen_"
df_starwars.iloc[9:15, 0] = "rank_"
df_starwars.iloc[15:29, 0] = "fav_"

df_starwars['newnames'] = df_starwars['variable'] + df_starwars['value']
df_starwars
df_other.columns = df_starwars['newnames']

```


## QUESTION|TASK 2

__Clean and format the data so that it can be used in a machine learning model.__ As you format the data, you should complete each item listed below. In your final report provide example(s) of the reformatted data with a short description of the changes made.  
    a. Filter the dataset to respondents that have seen at least one film  
    b. Create a new column that converts the age ranges to a single number. Drop the age range categorical column  
    c. Create a new column that converts the education groupings to a single number. Drop the school categorical column  
    d. Create a new column that converts the income ranges to a single number. Drop the income range categorical column  
    e. Create your target (also known as “y” or “label”) column based on the new income range column  
    f. One-hot encode all remaining categorical columns   

Data was simplified for machine learning use. In order to simplify groups certain values were changed. One-Hot encoding was used to change categorical for machine learning. For the different age ranges and incomes the average was taken from each range and assigned to each grouping. For education, numbers were assigned in ascending order according to level of education, also ascending. Finally a column was made to track households with income of $50k or more.

```{python}
#a

df_other.loc[(df_other['seen_Episode I'].str.len())>0,'seen_Episode I']=1
df_other.loc[(df_other['seen_Episode II'].str.len())>0,'seen_Episode II']=1
df_other.loc[(df_other['seen_Episode III'].str.len())>0,'seen_Episode III']=1
df_other.loc[(df_other['seen_Episode IV'].str.len())>0,'seen_Episode IV']=1
df_other.loc[(df_other['seen_Episode V'].str.len())>0,'seen_Episode V']=1
df_other.loc[(df_other['seen_Episode VI'].str.len())>0,'seen_Episode VI']=1

df_other[["seen_Episode I", "seen_Episode II", "seen_Episode III", "seen_Episode IV", "seen_Episode V", "seen_Episode VI"]] = df_other[["seen_Episode I", "seen_Episode II", "seen_Episode III", "seen_Episode IV", "seen_Episode V", "seen_Episode VI"]].replace(np.nan, 0)

df_other.loc[df_other['seen_Episode I']+df_other['seen_Episode II']+df_other['seen_Episode III']+df_other['seen_Episode IV']+df_other['seen_Episode V']+df_other['seen_Episode VI'] == 0,'Have you seen any of the 6 films in the Star Wars franchise?'] = 'No'

df_other.loc[df_other['seen_Episode I']+df_other['seen_Episode II']+df_other['seen_Episode III']+df_other['seen_Episode IV']+df_other['seen_Episode V']+df_other['seen_Episode VI'] != 0,'Have you seen any of the 6 films in the Star Wars franchise?'] = 'Yes'



#another approach
#roman_numerals = ['I','II','VI']
#for num in roman_numerals:
#     column_name = f'seen_Episode {num}'
#     df_...[column_name]=df...[column_name].apply(lambda x: 1 if pd.notna
#     (x) else x).fillna(0)
#



#df....replace(r'Star Wars:.*','1',regex = True,inplace = True)
#df...filter(regex = '^seen').fillna(0).astype('int')
```

```{python}
#b ages
age_dict = {
        '18-29' : 24,
        '30-44' : 37,
        '> 60'  : 60,
        '45-60' : 53,     
}

df_other['Age'] = df_other['Age'].map(age_dict)


```

```{python}
#c education
educ_dict = {
          'Less than high school degree' : 1,
          'High school degree' : 2,
          'Some college or Associate degree' : 3,
          'Bachelor degree' : 4,
          'Graduate degree' : 5

}
df_other['Education'] = df_other["Education"].map(educ_dict)

```

```{python}
#d income
income_dict = {
      '$0 - $24,999' : 12500,
      '$25,000 - $49,999' : 37500,
      '$50,000 - $99,999' : 74500,
      '$100,000 - $149,999' : 125000,
      '$150,000+' : 150000
      
}

df_other['Household Income'] = df_other['Household Income'].map(income_dict)

```

```{python}
#e


df_other['Target'] = 0

df_other.loc[df_other['Household Income'] > 50000, 'Target'] = 1

columns_to_drop = [col for col in df_other.columns if col == 1]
df_other = df_other.drop(columns=columns_to_drop)

```

```{python}
#f get_dummies
df_other = pd.get_dummies(
    df_other,
    columns=[
        'Have you seen any of the 6 films in the Star Wars franchise?',
        'Do you consider yourself to be a fan of the Star Wars film franchise?',
        'fav_Han Solo',
        'fav_Luke Skywalker',
        'fav_Princess Leia Organa',
        'fav_Anakin Skywalker',
        'fav_Obi Wan Kenobi',
        'fav_Emperor Palpatine',
        'fav_Darth Vader',
        'fav_Lando Calrissian',
        'fav_Boba Fett',
        'fav_C-3P0',
        'fav_R2 D2',
        'fav_Jar Jar Binks',
        'fav_Padme Amidala',
        'fav_Yoda',
        'Which character shot first?',
        'Are you familiar with the Expanded Universe?',
        'Do you consider yourself to be a fan of the Expanded Universe?',
        'Do you consider yourself to be a fan of the Star Trek franchise?',
        'Gender',
        'Location (Census Region)'
    ]
)



```

## QUESTION|TASK 3

__Validate that the data provided on GitHub lines up with the article by recreating 2 of the visuals from the article.__  

The tricky part was making the percentages and then double checking the articles. I had to change the parameters to only include the quanitity listed in the articles. 

```{python}

from lets_plot import *
import matplotlib.pyplot as plt

episodes_columns = ['seen_Episode I', 'seen_Episode II', 'seen_Episode III', 'seen_Episode IV', 'seen_Episode V', 'seen_Episode VI']


seen_any = df_other[episodes_columns].sum(axis=1) > 0
df_filtered = df_other[seen_any].iloc[:835] 

percentages = {}
total_respondents = len(df_filtered)

for col in episodes_columns:
    seen_count = df_filtered[col].sum()
    percentages[col] = (seen_count / total_respondents) * 100


episodes = [col.replace('seen_', '') for col in episodes_columns]
percent_values = [percentages[col] for col in episodes_columns]


plt.figure(figsize=(10, 6))
plt.barh(episodes, percent_values, color='steelblue')
plt.xlabel('Percentage (%)')
plt.ylabel('Episode')
plt.title('Percentage of Respondents Who Have Seen Each Star Wars Episode\nBased on first 835 respondents who have seen any film')
plt.tight_layout()
plt.show()





```

```{python}
# Include and execute your code here
import matplotlib.pyplot as plt

ranking_columns = ['rank_Episode I', 'rank_Episode II', 'rank_Episode III', 
                  'rank_Episode IV', 'rank_Episode V', 'rank_Episode VI']
episodes_columns = ['seen_Episode I', 'seen_Episode II', 'seen_Episode III', 
                   'seen_Episode IV', 'seen_Episode V', 'seen_Episode VI']

seen_all = (df_other[episodes_columns] == 1).all(axis=1)
df_filtered = df_other[seen_all].iloc[:471]

percentages = {}
total_respondents = len(df_filtered)

for col in ranking_columns:
    rank_one_count = (df_filtered[col] == 1).sum()
    percentages[col] = (rank_one_count / total_respondents) * 100

episodes = [col.replace('rank_', '') for col in ranking_columns]
percent_values = [percentages[col] for col in ranking_columns]

episode_order = ['Episode VI', 'Episode V', 'Episode IV', 'Episode III', 'Episode II', 'Episode I']

ordered_data = []
for ep in episode_order:
    idx = episodes.index(ep)
    ordered_data.append((ep, percent_values[idx]))

ordered_episodes, ordered_percentages = zip(*ordered_data)

plt.figure(figsize=(10, 6))
bars = plt.barh(ordered_episodes, ordered_percentages, color='steelblue')

for i, bar in enumerate(bars):
    plt.text(bar.get_width() + 0.5, bar.get_y() + bar.get_height()/2, 
             f"{ordered_percentages[i]:.1f}%", 
             va='center')

plt.xlabel('Percentage (%)')
plt.ylabel('')
plt.title('Percentage of People Who Ranked Each Star Wars Episode as #1\nBased on first 471 respondents who have seen all films')
plt.xlim(0, max(ordered_percentages) * 1.15)
plt.tight_layout()
plt.show()


```

## QUESTION|TASK 4

__Build a machine learning model that predicts whether a person makes more than $50k. Describe your model and report the accuracy.__ 

These machine learning model to predict whether a participant's household income is more than $50k is not perfect, with an accuracy/F1 scores around 0.63. I'm not sure if more columns should be dropped or not. 

```{python}
# Include and execute your code here
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import accuracy_score, classification_report
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression


df_clean = df_other.dropna()



numeric_cols = df_other.select_dtypes(include=['int64', 'float64']).columns
df_imputed = df_other.copy()

for col in numeric_cols:
    df_imputed[col] = df_imputed[col].fillna(df_imputed[col].median())


categorical_cols = df_other.select_dtypes(include=['object']).columns
for col in categorical_cols:
    df_imputed[col] = df_imputed[col].fillna(df_imputed[col].mode()[0])


df_ml = df_imputed 


features = df_ml.drop(columns=['Target', 'Household Income','RespondentID'])


X = features
y = df_ml['Target']




X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.25, random_state=42, stratify=y)


numeric_cols = X_train.select_dtypes(include=['int64', 'float64']).columns
scaler = StandardScaler()
X_train[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])
X_test[numeric_cols] = scaler.transform(X_test[numeric_cols])


rf_model = RandomForestClassifier(
    n_estimators=400, 
    max_depth=10,
    min_samples_split=5,
    class_weight='balanced',
    criterion='gini',
    random_state=42
)
rf_model.fit(X_train, y_train)


y_pred_rf = rf_model.predict(X_test)
print(f"\nRandom Forest Test Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}")
print("\nClassification Report (Random Forest):")
print(classification_report(y_test, y_pred_rf))


feature_importance = pd.DataFrame({
    'Feature': X.columns,
    'Importance': rf_model.feature_importances_
}).sort_values('Importance', ascending=False)
print("\nTop 10 Most Important Features:")
print(feature_importance.head(5))


print("\nModel Description:")
print("This Random Forest classifier was trained to predict whether a respondent's income exceeds $50,000.")
print(f"The model achieved an accuracy of {accuracy_score(y_test, y_pred_rf):.4f} on the test set.")

```

---

## STRETCH QUESTION|TASK 1

__Build a machine learning model that predicts whether a person makes more than $50k. With accuracy of at least 65%. Describe your model and report the accuracy.__

In my attemps to improve the model i tried to drop the participants who hadn't seen any movie. This dropped the accuracy scores significantly. from 0.63 to 0.56. I'm not sure what I could do to improve the model at this point.

```{python}
# Include and execute your code here
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import accuracy_score, classification_report
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression

episodes_columns = ['seen_Episode I', 'seen_Episode II', 'seen_Episode III', 
                   'seen_Episode IV', 'seen_Episode V', 'seen_Episode VI']

seen_all = (df_other[episodes_columns] == 1).all(axis=1)
df_filtered = df_other[seen_all]

numeric_cols = df_filtered.select_dtypes(include=['int64', 'float64']).columns
df_imputed = df_filtered.copy()

for col in numeric_cols:
    df_imputed[col] = df_imputed[col].fillna(df_imputed[col].median())

categorical_cols = df_filtered.select_dtypes(include=['object']).columns
for col in categorical_cols:
    df_imputed[col] = df_imputed[col].fillna(df_imputed[col].mode()[0])

df_ml = df_imputed

features = df_ml.drop(columns=['Target', 'Household Income', 'RespondentID'])

X = features
y = df_ml['Target']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.25, random_state=42, stratify=y)

numeric_cols = X_train.select_dtypes(include=['int64', 'float64']).columns
scaler = StandardScaler()
X_train[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])
X_test[numeric_cols] = scaler.transform(X_test[numeric_cols])

rf_model = RandomForestClassifier(
    n_estimators=400,
    max_depth=10,
    min_samples_split=5,
    class_weight='balanced',
    criterion='gini',
    random_state=42
)
rf_model.fit(X_train, y_train)

y_pred_rf = rf_model.predict(X_test)
print(f"\nRandom Forest Test Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}")
print("\nClassification Report (Random Forest):")
print(classification_report(y_test, y_pred_rf))

feature_importance = pd.DataFrame({
    'Feature': X.columns,
    'Importance': rf_model.feature_importances_
}).sort_values('Importance', ascending=False)
print("\nTop 10 Most Important Features:")
print(feature_importance.head(5))

print("\nModel Description:")
print("This Random Forest classifier was trained to predict whether a respondent's income exceeds $50,000.")
print(f"The model achieved an accuracy of {accuracy_score(y_test, y_pred_rf):.4f} on the test set.")
print("This model was trained using only respondents who have seen all six Star Wars films.")


```


## STRETCH QUESTION|TASK 2

__Validate the data provided on GitHub lines up with the article by recreating a 3rd visual from the article.__

_type your results and analysis here_

```{python}
# Include and execute your code here


```


## STRETCH QUESTION|TASK 3

__Create a new column that converts the location groupings to a single number. Drop the location categorical column.__  

_type your results and analysis here_

```{python}
# Include and execute your code here


```

---

